# Adversarial-Machine-Learning-Resources

## Papers

[Intriguing Properties of Machine Learning](https://arxiv.org/abs/1312.6199) - Christian Szegedy et al 2014 ICLR - **The first paper**

[Explaining and Harnessing Adversarial Examples](https://arxiv.org/pdf/1412.6572.pdf) - Ian Goodfellow, Christian Szegedy et al 2014

[Deep Neural Networks are easily fooled](https://arxiv.org/pdf/1412.1897.pdf) - Anh Nguyen et al CVPR 2015

[Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks](https://arxiv.org/abs/1511.04508) - Papernot et al 2015

[The Limitations of Deep Learning in Adversarial Settings](https://arxiv.org/abs/1511.07528) - Nicolash Papernot et al 2015

[Practical Black Box Attacks Against Machine Learning](https://arxiv.org/pdf/1602.02697.pdf)- Papernot, Goodfellow et al 2016

[Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples](https://arxiv.org/pdf/1605.07277.pdf) - Papernot and Goodfellow et al 2016

[Adversarial Examples in the Physical World](https://arxiv.org/pdf/1607.02533.pdf) - Kurakin et al ICLR 2017

[Adversarial Machine Learning at Scale](https://arxiv.org/pdf/1611.01236.pdf) - Kurakin et al ICLR 2017

[Ensemble Adversarial Training: Attacks and Defenses](https://arxiv.org/pdf/1705.07204.pdf) - Florian Tramer et al ICLR 2018

[Adversarial Examples: Attacks and Defenses for Deep Learning](https://arxiv.org/pdf/1712.07107.pdf) - Xiaoyong Yuan et al 2017


## Blogs

- https://ml.berkeley.edu/blog/2018/01/10/adversarial-examples/
- https://blog.openai.com/adversarial-example-research/
- https://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html

## Tools

- [Cleverhans](http://www.cleverhans.io/)
- [Cleverhans Github](https://github.com/tensorflow/cleverhans)
- [A Technical Report on Cleverhans](https://arxiv.org/pdf/1610.00768.pdf)

## Summary & Future Directions

[Adversarial Attacks and Defenses Competition](https://arxiv.org/pdf/1804.00097.pdf)

[Defense Against The Dark Arts](https://arxiv.org/pdf/1806.04169.pdf) - A summary of research till now and ongoing research was provided by Ian Goodfellow in a Workshop at some IEEE conference. He also mentioned several research avenues that could be explored in Adversarial Setting. 

To cite a quote from this [blog](http://www.cleverhans.io/security/privacy/ml/2017/02/15/why-attacking-machine-learning-is-easier-than-defending-it.html):
> Most defenses against adversarial examples that have been proposed so far just do not work very well at all, but the ones that do work are not adaptive. This means it is like they are playing a game of whack-a-mole: they close some vulnerabilities, but leave others open.
